{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "from yolov5 import val\n",
    "import sys\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "import reverse_geocoder as rg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Object Detection Dataset\n",
    "\n",
    "**Author:** Madhava Paliyam (madhavapaliyam@gmail.com)\n",
    "\n",
    "**Description:** Analyzes the model output using the YOLOv5 validation script. Breaks down model performance by crop type and region. \n",
    "\n",
    "\n",
    "\n",
    "**Inputs**: \n",
    "\n",
    "**Outputs**: \n",
    "\n",
    "This is done through the following steps: \n",
    "\n",
    "1. Get list of images that were used by using yaml config file\n",
    "2. Run YOLOV5 validation script on train/validation splits store to txt file\n",
    "3. From txt extract images and fix paths\n",
    "4. Access original images and get locations of images \n",
    "5. Split results by region, and then run the validation script on each region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SET PARAMETERS HERE #####\n",
    "\n",
    "# save output images here\n",
    "SAVE_FOLDER = 'runs/val'\n",
    "\n",
    "# exp name \n",
    "EXP_NAME = 'all'\n",
    "\n",
    "# yaml file describing data for trained model\n",
    "folder = os.path.abspath('dataset/')\n",
    "yaml_file = os.path.join(folder, 'data_info.yaml')\n",
    "\n",
    "# path to model weights \n",
    "model_weights_path = '/gpfs/data1/cmongp1/mpaliyam/street2sat/yolov5/runs/train/exp18/weights/best.pt'  \n",
    "\n",
    "# confidence threshold \n",
    "conf_thresh = .0001\n",
    "\n",
    "# IOU threshold\n",
    "iou_thresh = .1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs validation script with parameters\n",
    "\n",
    "https://github.com/ultralytics/yolov5/blob/63ddb6f0d06f6309aa42bababd08c859197a27af/val.py#L319\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-2-16 torch 1.10.2+cu102 CUDA:0 (Tesla V100-PCIE-16GB, 16160.5MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/gpfs/data1/cmongp1/mpaliyam/street2sat/data/DATASET_2022-02-28_01:13:06_474346/data_info.yaml, weights=['/gpfs/data1/cmongp1/mpaliyam/street2sat/yolov5/runs/train/exp18/weights/best.pt'], batch_size=25, imgsz=1000, conf_thres=0.0001, iou_thres=0.1, task=val, device=, single_cls=False, augment=False, verbose=True, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=all, exist_ok=True, half=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 369 layers, 20919810 parameters, 0 gradients, 48.2 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size 1000 must be multiple of max stride 32, updating to 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/gpfs/data1/cmongp1/mpaliyam/street2sat/data/DATASET_2022-02-28_01:13:06_474346/val/labels.cache' images and labels... 72 found, 0 missing, 35 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<?, ?it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         72        120      0.444      0.777      0.632        0.3\n",
      "              banana         72         10      0.631        0.8      0.791      0.389\n",
      "               maize         72         99      0.426      0.737      0.563      0.225\n",
      "           sugarcane         72          4      0.413          1      0.995      0.534\n",
      "             soybean         72          7      0.305      0.571      0.177     0.0521\n",
      "Speed: 0.3ms pre-process, 12.0ms inference, 2.0ms NMS per image at shape (25, 3, 1024, 1024)\n",
      "Results saved to \u001b[1mruns/val/all\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# runs the validate script from yolov5 libary\n",
    "to_parse = f\"val.py --data {yaml_file} \" \\\n",
    "            + f\"--weights {model_weights_path} \" \\\n",
    "            + f\"--batch-size {8} \" \\\n",
    "            + f\"--imgsz {800} \" \\\n",
    "            + f\"--conf-thres {conf_thresh} \" \\\n",
    "            + f\"--iou-thres {iou_thresh} \" \\\n",
    "            + f\"--verbose \" \\\n",
    "            + f\"--exist-ok \" \\\n",
    "            + f\"--task val\"\\\n",
    "\n",
    "to_parse = to_parse.split()\n",
    "sys.argv = to_parse \n",
    "val.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('../data/train.csv')\n",
    "val_set = pd.read_csv('../data/val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goes through each country and copies images from validation set that match the country into a new folder\n",
    "\n",
    "The new folders will be in the same directory as the dataset and will have the format [Country code] _ ANALYSIS _ [Dataset name]. There will also be a new yaml file associated with each new dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "126\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "# currently supported countries \n",
    "country_list = ['UG', 'KE', 'US']\n",
    "new_country_yaml_files = []\n",
    "\n",
    "def ignore_files(dir, files):\n",
    "    return [f for f in files if os.path.isfile(os.path.join(dir, f))]\n",
    "\n",
    "# goes through each country and makes a yolov5 compatible dataset by copying the correct files\n",
    "for country in country_list:\n",
    "    # selects only images from validation in the country \n",
    "    df_country = df[df['cc'] == country]\n",
    "    print(df_country.size)\n",
    "    # new dataset name for each country \n",
    "    new_dataset_name = country + '_ANALYSIS_' + dataset_name\n",
    "\n",
    "    config_val = config['val']\n",
    "    new_config_val = config_val.replace(dataset_name, new_dataset_name)\n",
    "\n",
    "    # copy directory structure \n",
    "    shutil.copytree(os.path.join(folder, dataset_name), os.path.join(folder,new_dataset_name), ignore=ignore_files)\n",
    "    \n",
    "    # for each validation image in the dataframe \n",
    "    for i,f in df_country.iterrows():\n",
    "        old_path_img = os.path.join(config_val, f['path'].replace(\"/\", \"*$\"))\n",
    "        new_path_img = os.path.join(new_config_val, f['path'].replace(\"/\", \"*$\"))\n",
    "        shutil.copy(old_path_img, new_path_img)\n",
    "\n",
    "        old_path_lab = os.path.join(config_val.replace('images', 'labels'), f['path'].replace(\"/\", \"*$\").replace('.JPG', '.txt'))\n",
    "        new_path_lab = os.path.join(new_config_val.replace('images', 'labels'), f['path'].replace(\"/\", \"*$\").replace('.JPG', '.txt'))\n",
    "        shutil.copy(old_path_lab, new_path_lab)\n",
    "\n",
    "    # create new yaml file for the new country dataset \n",
    "    new_yaml_file = yaml_file.replace('data_info', f'data_info_{country}').replace(dataset_name, new_dataset_name)\n",
    "    new_config = config.copy()\n",
    "    # train is not used at all since there will be no training images copied, only validation \n",
    "    new_config['train'] = os.path.join(folder, new_dataset_name, 'train', 'images')\n",
    "    new_config['val'] = os.path.join(folder, new_dataset_name, 'val', 'images')\n",
    "    with open(new_yaml_file, 'w') as outfile:\n",
    "        yaml.dump(new_config, outfile, default_flow_style=False)\n",
    "\n",
    "    # keep track of new yaml files \n",
    "    new_country_yaml_files.append(new_yaml_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpfs/data1/cmongp1/mpaliyam/street2sat/data/UG_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_UG.yaml',\n",
       " '/gpfs/data1/cmongp1/mpaliyam/street2sat/data/KE_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_KE.yaml',\n",
       " '/gpfs/data1/cmongp1/mpaliyam/street2sat/data/US_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_US.yaml']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_country_yaml_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For each new dataset created above, it runs the validation script. This way the per country detection scores can be seen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-2-16 torch 1.10.2+cu102 CUDA:0 (Tesla V100-PCIE-16GB, 16160.5MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "RUNING VALIDATION SCRIPT: /gpfs/data1/cmongp1/mpaliyam/street2sat/data/UG_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_UG.yaml\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/gpfs/data1/cmongp1/mpaliyam/street2sat/data/UG_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_UG.yaml, weights=['/gpfs/data1/cmongp1/mpaliyam/street2sat/yolov5/runs/train/exp18/weights/best.pt'], batch_size=25, imgsz=1000, conf_thres=0.0001, iou_thres=0.1, task=val, device=, single_cls=False, augment=False, verbose=True, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=UG, exist_ok=True, half=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 369 layers, 20919810 parameters, 0 gradients, 48.2 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size 1000 must be multiple of max stride 32, updating to 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/gpfs/data1/cmongp1/mpaliyam/street2sat/data/UG_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/val/labels' images and labels...40 found, 0 missing, 22 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 767.87it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /gpfs/data1/cmongp1/mpaliyam/street2sat/data/UG_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/val/labels.cache\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         40         60      0.702       0.78      0.744      0.332\n",
      "              banana         40         10      0.738        0.8      0.792       0.39\n",
      "               maize         40         50      0.665       0.76      0.696      0.274\n",
      "Speed: 0.3ms pre-process, 12.0ms inference, 1.7ms NMS per image at shape (25, 3, 1024, 1024)\n",
      "Results saved to \u001b[1mruns/val/UG\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RUNING VALIDATION SCRIPT: /gpfs/data1/cmongp1/mpaliyam/street2sat/data/KE_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_KE.yaml\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/gpfs/data1/cmongp1/mpaliyam/street2sat/data/KE_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_KE.yaml, weights=['/gpfs/data1/cmongp1/mpaliyam/street2sat/yolov5/runs/train/exp18/weights/best.pt'], batch_size=25, imgsz=1000, conf_thres=0.0001, iou_thres=0.1, task=val, device=, single_cls=False, augment=False, verbose=True, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=KE, exist_ok=True, half=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-2-16 torch 1.10.2+cu102 CUDA:0 (Tesla V100-PCIE-16GB, 16160.5MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 369 layers, 20919810 parameters, 0 gradients, 48.2 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size 1000 must be multiple of max stride 32, updating to 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/gpfs/data1/cmongp1/mpaliyam/street2sat/data/KE_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/val/labels' images and labels...18 found, 0 missing, 5 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 1537.44it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /gpfs/data1/cmongp1/mpaliyam/street2sat/data/KE_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/val/labels.cache\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         18         35       0.41      0.656      0.411      0.164\n",
      "               maize         18         35       0.41      0.656      0.411      0.164\n",
      "Speed: 0.3ms pre-process, 12.2ms inference, 1.7ms NMS per image at shape (25, 3, 1024, 1024)\n",
      "Results saved to \u001b[1mruns/val/KE\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-2-16 torch 1.10.2+cu102 CUDA:0 (Tesla V100-PCIE-16GB, 16160.5MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RUNING VALIDATION SCRIPT: /gpfs/data1/cmongp1/mpaliyam/street2sat/data/US_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_US.yaml\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/gpfs/data1/cmongp1/mpaliyam/street2sat/data/US_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_US.yaml, weights=['/gpfs/data1/cmongp1/mpaliyam/street2sat/yolov5/runs/train/exp18/weights/best.pt'], batch_size=25, imgsz=1000, conf_thres=0.0001, iou_thres=0.1, task=val, device=, single_cls=False, augment=False, verbose=True, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=US, exist_ok=True, half=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 369 layers, 20919810 parameters, 0 gradients, 48.2 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size 1000 must be multiple of max stride 32, updating to 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/gpfs/data1/cmongp1/mpaliyam/street2sat/data/US_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/val/labels' images and labels...14 found, 0 missing, 8 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 67.64it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /gpfs/data1/cmongp1/mpaliyam/street2sat/data/US_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/val/labels.cache\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         14         25      0.434      0.786      0.499      0.255\n",
      "               maize         14         14      0.303      0.786      0.322      0.179\n",
      "           sugarcane         14          4      0.694          1      0.995      0.534\n",
      "             soybean         14          7      0.305      0.571      0.178     0.0526\n",
      "Speed: 0.3ms pre-process, 13.1ms inference, 4.2ms NMS per image at shape (25, 3, 1024, 1024)\n",
      "Results saved to \u001b[1mruns/val/US\u001b[0m\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# runs validation script on each of the country\n",
    "for country_yaml_file in new_country_yaml_files:\n",
    "    print(f\"\\n\\n\\n\\nRUNING VALIDATION SCRIPT: {country_yaml_file}\\n\\n\\n\")\n",
    "    # gets the country code\n",
    "    exp_name = country_yaml_file.split('_')[0][-2:]\n",
    "    # runs the validate script from yolov5 libary\n",
    "    to_parse = f\"val.py --data {country_yaml_file} \" \\\n",
    "                + f\"--weights {model_weights_path} \" \\\n",
    "                + f\"--batch-size {batch_size} \" \\\n",
    "                + f\"--imgsz {img_size} \" \\\n",
    "                + f\"--conf-thres {conf_thresh} \" \\\n",
    "                + f\"--iou-thres {iou_thresh} \" \\\n",
    "                + f\"--project {save_folder} \"\\\n",
    "                + f\"--name {exp_name} \"\\\n",
    "                + f\"--verbose \" \\\n",
    "                + f\"--exist-ok \" \\\n",
    "                + f\"--task val\"\\\n",
    "\n",
    "    to_parse = to_parse.split()\n",
    "    sys.argv = to_parse \n",
    "    val.main()\n",
    "\n",
    "    print(\"------------------------------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18299326acd67c3347301aa46e10944c681f8646864aedc6c136bb4609b8c46d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('lacuna')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

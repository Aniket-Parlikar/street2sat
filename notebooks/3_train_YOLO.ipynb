{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import os \n",
    "from yolov5 import train \n",
    "import sys \n",
    "import yaml\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train YOLO v5\n",
    "\n",
    "**Author:** Madhava Paliyam (madhavapaliyam@gmail.com)\n",
    "\n",
    "**Description:** Downloads the images from train.csv and val.csv and trains a YOLO model on it. \n",
    "\n",
    "**Inputs**: Folder to save dataset to \n",
    "\n",
    "**Outputs**: Trained Model Weights\n",
    "\n",
    "This is done through the following steps: \n",
    "\n",
    "NOTE: First perform a dvc pull in the repository to get the most up to date train/val sets\n",
    "\n",
    "1. Read and download images to local directory\n",
    "2. Run YOLOv5 Training Script\n",
    "3. Run YOLOv5 Validation Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SET PARAMETERS HERE #####\n",
    "FOLDER = 'dataset'\n",
    "\n",
    "\n",
    "!dvc pull -q -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and download images to local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('../data/train.csv')\n",
    "val_set = pd.read_csv('../data/val.csv')\n",
    "\n",
    "client = storage.Client()\n",
    "gcloud_uploaded_bucket = client.bucket('street2sat-uploaded')\n",
    "\n",
    "# This function downloads the images into directories as needed for training YOLO\n",
    "def download_to_folder(folder, dataset):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(os.path.join(folder, 'images'))\n",
    "        os.makedirs(os.path.join(folder, 'labels'))\n",
    "\n",
    "    for i,image in dataset.iterrows():\n",
    "        # download image to directory \n",
    "        path = image['path'].replace('gs://street2sat-uploaded/', '')\n",
    "        blob = gcloud_uploaded_bucket.blob(path)\n",
    "        blob.download_to_filename(os.path.join(folder,'images',str(i) + '.jpg'))\n",
    "        \n",
    "        # create txt file and download \n",
    "        if isinstance(image['bounding_boxes'], str): \n",
    "            with open(os.path.join(folder, 'labels', str(i) + '.txt'), 'w') as f: \n",
    "                f.write(image['bounding_boxes'])\n",
    "                \n",
    "\n",
    "download_to_folder(os.path.join(FOLDER, 'train'), train_set)\n",
    "download_to_folder(os.path.join(FOLDER, 'val'), val_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the classes to index dictionary\n",
    "classes_dict = OrderedDict()\n",
    "with open('../street2sat_utils/crop_info/classes.txt') as classes_file: \n",
    "    for i, line in enumerate(classes_file):\n",
    "        classes_dict[line.strip()] = i\n",
    "\n",
    "\n",
    "# Create yaml file \n",
    "path = os.path.abspath(FOLDER)\n",
    "training_yaml = {'train' : os.path.join(path, 'train', 'images'), \n",
    "                    'val' : os.path.join(path, 'val', 'images'), \n",
    "                    'nc' : len(classes_dict), \n",
    "                    'names' : list(classes_dict.keys())}\n",
    "\n",
    "with open(f\"{FOLDER}/data_info.yaml\", 'w') as file: \n",
    "    yaml.dump(training_yaml, file, default_flow_style=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run YOLOv5 Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=dataset/data_info.yaml, hyp=, epochs=2, batch_size=8, imgsz=600, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=cpu, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, mmdet_tags=False, entity=None, bbox_interval=-1, artifact_alias=latest, neptune_token=None, neptune_project=None, s3_upload_dir=None, upload_dataset=False, batch=2\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs\n",
      "\u001b[34m\u001b[1mNeptune AI: \u001b[0mrun 'pip install neptune-client' to automatically track and visualize YOLOv5 ðŸš€ runs\n",
      "WARNING: --img-size 600 must be multiple of max stride 32, updating to 608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/gpfs/data1/cmongp1/mpaliyam/street2sat/street2sat/notebooks/dataset/train/labels.cache' images and labels... 206 found, 177 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 383/383 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/gpfs/data1/cmongp1/mpaliyam/street2sat/street2sat/notebooks/dataset/val/labels.cache' images and labels... 60 found, 33 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93/93 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.71, Best Possible Recall (BPR) = 0.9976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0/1    0.363G   0.06912  0.009045   0.02482        48       608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [05:35<00:00,  7.00s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:34<00:00,  5.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         93          0          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/1    0.363G   0.06846  0.008906    0.0245        32       608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [04:53<00:00,  6.11s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:28<00:00,  4.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         93          0          0          0          0          0\n",
      "Optimizer stripped from runs/train/exp13/weights/last.pt, 14.4MB\n",
      "Optimizer stripped from runs/train/exp13/weights/best.pt, 14.4MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:28<00:00,  4.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         93          0          0          0          0          0\n"
     ]
    }
   ],
   "source": [
    "# runs the detect script from yolov5 libary\n",
    "# change run parameters here if doing experiments: \n",
    "# Full list here: https://github.com/ultralytics/yolov5/blob/master/train.py\n",
    "\n",
    "train.run(data = f'{FOLDER}/data_info.yaml', imgsz = 800, weights = 'yolov5s.pt', multi_scale = False, batch = 2, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move model weights to folder and commit to dvc "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18299326acd67c3347301aa46e10944c681f8646864aedc6c136bb4609b8c46d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('lacuna')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

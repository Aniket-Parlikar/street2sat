{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0c03ff",
   "metadata": {},
   "source": [
    "# Setting up a labeling task for Street2Sat\n",
    "This notebook provides code and necessary instructions for creating a street2sat labeling task from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19914c68",
   "metadata": {},
   "source": [
    "## 1. Generating list of random images to label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f3ae3d",
   "metadata": {},
   "source": [
    "#### 1a. Connect to Gcloud and get all image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9860b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from google.cloud import aiplatform, firestore, storage\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import collections\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb27283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to run the below commands to authenticate GCloud and set the correct project\n",
    "# !gcloud auth login\n",
    "# !gcloud config set project bsos-geog-harvest1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1676755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize connections to cloud storage and database\n",
    "client = storage.Client()\n",
    "db = firestore.Client()\n",
    "coll = db.collection(\"street2sat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76f59a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988114f20ab741a08f8a158d0cf377a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in all available paths, this will take 3 minutes or so\n",
    "all_paths = [blob.name for blob in tqdm(client.list_blobs('street2sat-uploaded', prefix=\"\"))]  \n",
    "random.shuffle(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76955b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "cached = {}\n",
    "csv_bucket = \"street2sat-gcloud-labeling\"\n",
    "\n",
    "def get_images_already_being_labelled():\n",
    "    \"\"\"Gets images already labelled\"\"\"\n",
    "    images_already_being_labelled = []\n",
    "    csv_names = [blob.name for blob in client.list_blobs(csv_bucket, prefix=\"\") if blob.name.endswith(\".csv\")]\n",
    "\n",
    "    for csv_name in tqdm(csv_names, desc=\"Get already labelled\"):\n",
    "        uris = pd.read_csv(f\"gs://{csv_bucket}/{csv_name}\", header=None, sep=\"\\n\")[0]\n",
    "        images_already_being_labelled += uris.to_list()\n",
    "\n",
    "    # Ensure there are no duplicates in images already being labelled\n",
    "    dupes = [item for item, count in collections.Counter(images_already_being_labelled).items() if count > 1]\n",
    "    dupes.remove('0') # An index of 0 was erroneously output in previous csv\n",
    "    assert len(dupes) == 0, \"Found duplicates in images being labelled. One of the labeling tasks needs to be removed.\"\n",
    "    return images_already_being_labelled\n",
    "\n",
    "def amount_of_objects_detected(uri: str):\n",
    "    \"\"\"Finds amount of objects detected in image uri\"\"\"\n",
    "    if uri in cached:\n",
    "        return cached[uri]\n",
    "    \n",
    "    query = coll.where(\"input_img\", \"==\", uri).limit(1).get()\n",
    "    objects_detected = 0\n",
    "    if len(query) > 0:\n",
    "        item = query[0].to_dict()\n",
    "        if \"results\" in item:\n",
    "            objects_detected = len(item[\"results\"])\n",
    "    \n",
    "    cached[uri] = objects_detected     \n",
    "    return objects_detected\n",
    "\n",
    "def get_paths_with_predicted_objects(amount: int, object_threshold: int = 5):\n",
    "    \"\"\"Gets URIs for images with more than {object_threshold} objects\"\"\"\n",
    "    already_being_labelled = get_images_already_being_labelled()\n",
    "    images_to_label = []\n",
    "    with tqdm(total=amount, desc=\"Get URIs\") as pbar:\n",
    "        for i, p in enumerate(all_paths):\n",
    "            uri = f\"gs://street2sat-uploaded/{p}\"\n",
    "            if uri in already_being_labelled or amount_of_objects_detected(uri) <= object_threshold:\n",
    "                continue\n",
    "            pbar.update(1)\n",
    "            images_to_label.append(uri)\n",
    "            if len(images_to_label) == 1:\n",
    "                print(f\"Start range: {i}\")\n",
    "            if len(images_to_label) >= amount:\n",
    "                print(f\"End range: {i}\")\n",
    "                break\n",
    "    return images_to_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e93afe",
   "metadata": {},
   "source": [
    "#### 1b. Generate CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "61aa9543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495973ec2a424cff811adb88ced4d09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CSV Generation:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de982d2e50340af92c07a3239e1ebf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Get already labelled:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adcafab4e8bc49f8a086f8bf7d540cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Get URIs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start range: 6003\n",
      "End range: 6528\n",
      "Saving to 2021-11-22_13-3-20.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175ea1ca534049efbed9d6fd2f057d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Get already labelled:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87124cb9a8348b8b8e87be07cf713a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Get URIs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start range: 6537\n",
      "End range: 7037\n",
      "Saving to 2021-11-22_13-3-48.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a9187a20ff40c5b5af8d3646e93002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Get already labelled:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81891dbdab04596a0d501739ef31f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Get URIs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start range: 7038\n",
      "End range: 7547\n",
      "Saving to 2021-11-22_13-4-20.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f4dc30f4bb4f668d0e52d93526c291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Get already labelled:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b3cdfded7841df9ca8794d048042d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Get URIs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start range: 7553\n",
      "End range: 8067\n",
      "Saving to 2021-11-22_13-4-47.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d39d0ffb75469caad008d261434633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Get already labelled:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99837d91cc364daea1cd3a4bc08aa98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Get URIs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start range: 8068\n",
      "End range: 8660\n",
      "Saving to 2021-11-22_13-5-19.csv\n"
     ]
    }
   ],
   "source": [
    "amount_of_csvs_to_generate = 5\n",
    "for i in tqdm(range(amount_of_csvs_to_generate), desc=\"CSV Generation\"):\n",
    "    # Get random images to label with at least 5 objects predicted in each image\n",
    "    images_to_label = get_paths_with_predicted_objects(100, object_threshold=5)\n",
    "    csv_name = datetime.now().strftime(date_format) + \".csv\"\n",
    "    print(f\"Saving to {csv_name}\")\n",
    "    df = pd.DataFrame(images_to_label)\n",
    "    df.to_csv(f\"gs://{csv_bucket}/{csv_name}\", sep=\"\\n\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b27e0",
   "metadata": {},
   "source": [
    "## 2. Creating a dataset on Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "be417b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 csvs_for_new_datasets\n"
     ]
    }
   ],
   "source": [
    "# Finds which csvs to make \n",
    "existing_dataset_dates = []\n",
    "for d in aiplatform.ImageDataset.list():\n",
    "    cleaned_display_name = d.display_name.replace(\" \", \"\") \n",
    "    existing_dataset_dates.append(datetime.strptime(cleaned_display_name, \"%Y-%m-%d_%H-%M-%S\"))\n",
    "\n",
    "csvs_for_new_datasets = []\n",
    "for blob in client.list_blobs(csv_bucket, prefix=\"\"):\n",
    "    if not blob.name.endswith(\".csv\"):\n",
    "        continue\n",
    "    csv_date = datetime.strptime(Path(blob.name).stem, \"%Y-%m-%d_%H-%M-%S\")\n",
    "    if csv_date in existing_dataset_dates:\n",
    "        continue\n",
    "    csvs_for_new_datasets.append(blob)\n",
    "print(f\"Found {len(csvs_for_new_datasets)} csvs_for_new_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "33ae0514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/7294626331596161024/operations/1088044889729400832\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/7294626331596161024\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/7294626331596161024')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/7294626331596161024\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/7294626331596161024/operations/3587542682920026112\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/6605575588608475136/operations/5470047327160893440\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/6605575588608475136\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/6605575588608475136')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/6605575588608475136\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/6605575588608475136/operations/1718548837561270272\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/7033417553208672256/operations/1860412225823440896\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/7033417553208672256\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/7033417553208672256')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/7033417553208672256\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/7033417553208672256/operations/8750919655700299776\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/4644257950888624128/operations/1268188874824220672\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/4644257950888624128\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/4644257950888624128')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/4644257950888624128\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/4644257950888624128/operations/8199228701347414016\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/4299732579394781184/operations/2011282813340352512\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/4299732579394781184\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/4299732579394781184')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/4299732579394781184\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/4299732579394781184/operations/5699730908156788736\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/2338414941674930176/operations/5879874893251608576\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/2338414941674930176\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/2338414941674930176')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/2338414941674930176\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/2338414941674930176/operations/194080363696357376\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/6963611758984429568/operations/392238747300659200\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/6963611758984429568\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/6963611758984429568')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/6963611758984429568\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/6963611758984429568/operations/5969946885799018496\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/1268810030174437376/operations/4166255235037134848\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/1268810030174437376\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/1268810030174437376')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/1268810030174437376\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/1268810030174437376/operations/4805766382123745280\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/8564641426514640896/operations/6330234855988658176\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/8564641426514640896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/8564641426514640896')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/8564641426514640896\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/8564641426514640896/operations/5003924765728047104\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/1199004235950194688/operations/2698081756514353152\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/1530018808561926144/operations/3393887898943094784\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/1199004235950194688\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/1199004235950194688')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/1199004235950194688\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/1199004235950194688/operations/3574031884037914624\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/1530018808561926144\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/1530018808561926144')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/1530018808561926144\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/1530018808561926144/operations/8005573917370482688\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/16809333765439488/operations/8275789895012712448\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/16809333765439488\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/16809333765439488')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/16809333765439488\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/16809333765439488/operations/781800115068207104\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/6141704826989314048/operations/2240966394336247808\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/6141704826989314048\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/6141704826989314048')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/6141704826989314048\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/6141704826989314048/operations/2499923372910051328\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/4304236179022151680/operations/7111609391337439232\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/4304236179022151680\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/4304236179022151680')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/4304236179022151680\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/4304236179022151680/operations/7309767774941741056\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating ImageDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create ImageDataset backing LRO: projects/1012768714927/locations/us-central1/datasets/6950100960102318080/operations/8185717902465302528\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ImageDataset created. Resource name: projects/1012768714927/locations/us-central1/datasets/6950100960102318080\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this ImageDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.ImageDataset('projects/1012768714927/locations/us-central1/datasets/6950100960102318080')\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Importing ImageDataset data: projects/1012768714927/locations/us-central1/datasets/6950100960102318080\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Import ImageDataset data backing LRO: projects/1012768714927/locations/us-central1/datasets/6950100960102318080/operations/6852652412763635712\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "new_datasets = []\n",
    "for csv_for_dataset in csvs_for_new_datasets:\n",
    "    display_name = Path(csvs_for_new_datasets[0].name).stem\n",
    "    assert datetime.strptime(display_name, \"%Y-%m-%d_%H-%M-%S\")\n",
    "        \n",
    "    ds = aiplatform.ImageDataset.create(\n",
    "        display_name=display_name,\n",
    "        gcs_source=f\"gs://{csv_for_dataset.bucket.name}/{csv_for_dataset.name}\",\n",
    "        import_schema_uri=aiplatform.schema.dataset.ioformat.image.bounding_box,\n",
    "        sync=False,\n",
    "    )\n",
    "    new_datasets.append(ds)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "38949d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing: 0/15\n"
     ]
    }
   ],
   "source": [
    "# Check status\n",
    "done = len([_ for _ in new_datasets if ds._gca_resource])\n",
    "total = len(new_datasets)\n",
    "print(f\"Completed processing: {done}/{total}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d2e54d",
   "metadata": {},
   "source": [
    "## 3. Creating a labeling task\n",
    "You can create a labeling task during or after dataset creation is complete.\n",
    "\n",
    "a. Click **CREATE LABELING TASK**\n",
    "\n",
    "b. For Labeling Task name: use the `%Y-%m-%d_%H-%-M-%S` format with a task suffix\n",
    "\n",
    "![image.png](../assets/labeling-task/3b.png)\n",
    "\n",
    "c. In step 2: input the labels as per [classes.txt](https://github.com/nasaharvest/street2sat_website/blob/main/street2sat_utils/crop_info/classes.txt)\n",
    "\n",
    "![image-2.png](../assets/labeling-task/3c.png)\n",
    "\n",
    "d. In step 3: select the instruction PDF available in `gs://street2sat-gcloud-labeling`. (This can be updated if necessary)\n",
    "\n",
    "![image-3.png](../assets/labeling-task/3d.png)\n",
    "\n",
    "e. In step 4: select the \"Street2sat Labelers\" group and add your email as a manager.\n",
    "\n",
    "![image-4.png](../assets/labeling-task/3e.png)\n",
    "\n",
    "f. After some time (maybe 15 minutes) you should receive an email from noreply-vertexai@google.com that looks like this:\n",
    "![image-6.png](../assets/labeling-task/3f.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f16ab1b",
   "metadata": {},
   "source": [
    "## 4. Labeling Manager Console\n",
    "Using the second link the above email you can access the Manager console. \n",
    "- Tasks - shows the progress of the created Labeling task\n",
    "- Specialists - shows the list of available labelers (more can be added here)\n",
    "- Assignments - allows managing who is working on which task\n",
    "\n",
    "Tasks and Specialists are pretty intuitive, but to change Assignment you must:\n",
    "1. Populate the Specialists column with an existing specialist (labeler)\n",
    "2. Populate the Tasks column with a created task\n",
    "3. Make changes by checking or unchecking specialists\n",
    "4. Commit changes using the button on the top right\n",
    "\n",
    "![image.png](../assets/labeling-task/4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfaeb8",
   "metadata": {},
   "source": [
    "# 5. Actual labeling\n",
    "Members of the Street2sat labelers group should receive an email like this upon assignment:\n",
    "![image.png](../assets/labeling-task/5.png)\n",
    "\n",
    "However these emails have not been consistent so a direct link from Step 3f email may need to be manually sent.\n",
    "\n",
    "Once the specialist clicks the link, they'll see the following page and will be ready to go:\n",
    "![image-2.png](../assets/labeling-task/5b.png)\n",
    "\n",
    "- Since this guide is for individuals creating labeling tasks, I'll leave details about actual labeling on Google Cloud to another slide/document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c96207",
   "metadata": {},
   "source": [
    "## 6. Exporting the labels\n",
    "To export labels navigate to Vertex AI datasets, click the 3 dots on the desirable dataset and select Export dataset\n",
    "![image.png](../assets/labeling-task/6.png)\n",
    "\n",
    "Save the output file directly to the `street2sat-gcloud-labeling` bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fd8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import firestore\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from yolov5 import val\n",
    "import sys\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "import reverse_geocoder as rg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to Gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize connections to cloud storage and database\n",
    "# !gcloud auth login\n",
    "# !gcloud config set account <>\n",
    "# !gcloud config set project bsos-geog-harvest1\n",
    "# !gcloud auth application-default login\n",
    "client = storage.Client()\n",
    "db = firestore.Client()\n",
    "gcloud_labeling_bucket_str = 'street2sat-gcloud-labeling'\n",
    "coll = db.collection(\"street2sat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model Prediction Results By Country And Crop\n",
    "\n",
    "1. Get list of images that were used by using yaml config file\n",
    "2. Run YOLOV5 validation script on train/validation splits store to txt file\n",
    "3. From txt extract images and fix paths\n",
    "4. Access original images and get locations of images \n",
    "5. Split results by region, and then run the validation script on each region. \n",
    "\n",
    "\n",
    "This notebook is to be run on the same machine as where the dataset and the model trained weights are located. Those paths can be configured below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output images here\n",
    "save_folder = 'runs/val'\n",
    "\n",
    "# exp name \n",
    "exp_name = 'all'\n",
    "\n",
    "# yaml file describing data for trained model\n",
    "folder = '/gpfs/data1/cmongp1/mpaliyam/street2sat/data'\n",
    "dataset_name = 'DATASET_2022-02-28_01:13:06_474346'\n",
    "yaml_file = os.path.join(folder, dataset_name, 'data_info.yaml')\n",
    "\n",
    "# path to model weights \n",
    "model_weights_path = '/gpfs/data1/cmongp1/mpaliyam/street2sat/yolov5/runs/train/exp18/weights/best.pt'  \n",
    "\n",
    "# batch size \n",
    "batch_size = 25\n",
    "\n",
    "# image size \n",
    "img_size = 1000\n",
    "\n",
    "# confidence threshold \n",
    "conf_thresh = .0001\n",
    "\n",
    "# IOU threshold\n",
    "iou_thresh = .1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs validation script with parameters\n",
    "\n",
    "https://github.com/ultralytics/yolov5/blob/63ddb6f0d06f6309aa42bababd08c859197a27af/val.py#L319\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-2-16 torch 1.10.2+cu102 CUDA:0 (Tesla V100-PCIE-16GB, 16160.5MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/gpfs/data1/cmongp1/mpaliyam/street2sat/data/DATASET_2022-02-28_01:13:06_474346/data_info.yaml, weights=['/gpfs/data1/cmongp1/mpaliyam/street2sat/yolov5/runs/train/exp18/weights/best.pt'], batch_size=25, imgsz=1000, conf_thres=0.0001, iou_thres=0.1, task=val, device=, single_cls=False, augment=False, verbose=True, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=all, exist_ok=True, half=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 369 layers, 20919810 parameters, 0 gradients, 48.2 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size 1000 must be multiple of max stride 32, updating to 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/gpfs/data1/cmongp1/mpaliyam/street2sat/data/DATASET_2022-02-28_01:13:06_474346/val/labels.cache' images and labels... 72 found, 0 missing, 35 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<?, ?it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:09<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         72        120      0.444      0.777      0.632        0.3\n",
      "              banana         72         10      0.631        0.8      0.791      0.389\n",
      "               maize         72         99      0.426      0.737      0.563      0.225\n",
      "           sugarcane         72          4      0.413          1      0.995      0.534\n",
      "             soybean         72          7      0.305      0.571      0.177     0.0521\n",
      "Speed: 0.3ms pre-process, 12.0ms inference, 2.0ms NMS per image at shape (25, 3, 1024, 1024)\n",
      "Results saved to \u001b[1mruns/val/all\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# runs the validate script from yolov5 libary\n",
    "to_parse = f\"val.py --data {yaml_file} \" \\\n",
    "            + f\"--weights {model_weights_path} \" \\\n",
    "            + f\"--batch-size {batch_size} \" \\\n",
    "            + f\"--imgsz {img_size} \" \\\n",
    "            + f\"--conf-thres {conf_thresh} \" \\\n",
    "            + f\"--iou-thres {iou_thresh} \" \\\n",
    "            + f\"--project {save_folder} \"\\\n",
    "            + f\"--name {exp_name} \"\\\n",
    "            + f\"--verbose \" \\\n",
    "            + f\"--exist-ok \" \\\n",
    "            + f\"--task val\"\\\n",
    "\n",
    "to_parse = to_parse.split()\n",
    "sys.argv = to_parse \n",
    "val.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Opens yaml file and searches street2sat uploaded for images with same name. Finds locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>name</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>cc</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.15406</td>\n",
       "      <td>35.19878</td>\n",
       "      <td>Muhoroni</td>\n",
       "      <td>Kisumu</td>\n",
       "      <td></td>\n",
       "      <td>KE</td>\n",
       "      <td>gs://street2sat-uploaded/KENYA/2021_07_16_T2/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.34032</td>\n",
       "      <td>-85.3508</td>\n",
       "      <td>Eaton</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Delaware County</td>\n",
       "      <td>US</td>\n",
       "      <td>gs://street2sat-uploaded/USA/2021-08-20-cropto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47972</td>\n",
       "      <td>33.23444</td>\n",
       "      <td>Bugembe</td>\n",
       "      <td>Eastern Region</td>\n",
       "      <td>Jinja District</td>\n",
       "      <td>UG</td>\n",
       "      <td>gs://street2sat-uploaded/Uganda/1829244/2020-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.08209</td>\n",
       "      <td>34.17503</td>\n",
       "      <td>Mbale</td>\n",
       "      <td>Eastern Region</td>\n",
       "      <td>Mbale District</td>\n",
       "      <td>UG</td>\n",
       "      <td>gs://street2sat-uploaded/Uganda/2021-06-21_Eas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.13811</td>\n",
       "      <td>-84.58051</td>\n",
       "      <td>Paulding</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Paulding County</td>\n",
       "      <td>US</td>\n",
       "      <td>gs://street2sat-uploaded/USA/2021-08-20-cropto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat        lon      name          admin1           admin2  cc                                               path\n",
       "0  -0.15406   35.19878  Muhoroni          Kisumu                   KE  gs://street2sat-uploaded/KENYA/2021_07_16_T2/1...\n",
       "1  40.34032   -85.3508     Eaton         Indiana  Delaware County  US  gs://street2sat-uploaded/USA/2021-08-20-cropto...\n",
       "2   0.47972   33.23444   Bugembe  Eastern Region   Jinja District  UG  gs://street2sat-uploaded/Uganda/1829244/2020-0...\n",
       "3   1.08209   34.17503     Mbale  Eastern Region   Mbale District  UG  gs://street2sat-uploaded/Uganda/2021-06-21_Eas...\n",
       "4  41.13811  -84.58051  Paulding            Ohio  Paulding County  US  gs://street2sat-uploaded/USA/2021-08-20-cropto..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(yaml_file) as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "val_files = os.listdir(config['val'])\n",
    "# convert from street2sat gcloud labeling format to street2sat uploaded format \n",
    "val_files = [f.replace('*$', '/') for f in val_files]\n",
    "\n",
    "# find all images and obtain metadata\n",
    "locations = []\n",
    "for val_file in val_files:\n",
    "    query = coll.where(\"input_img\", \"==\", val_file).limit(1).get()\n",
    "    loc = query[0].to_dict()['coord']\n",
    "    loc = tuple(loc)\n",
    "    locations.append(loc)\n",
    "\n",
    "# search for image location\n",
    "results = rg.search(locations)\n",
    "df = pd.DataFrame(results)\n",
    "df['path'] = val_files\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goes through each country and copies images from validation set that match the country into a new folder\n",
    "\n",
    "The new folders will be in the same directory as the dataset and will have the format [Country code] _ ANALYSIS _ [Dataset name]. There will also be a new yaml file associated with each new dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n",
      "126\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "# currently supported countries \n",
    "country_list = ['UG', 'KE', 'US']\n",
    "new_country_yaml_files = []\n",
    "\n",
    "def ignore_files(dir, files):\n",
    "    return [f for f in files if os.path.isfile(os.path.join(dir, f))]\n",
    "\n",
    "# goes through each country and makes a yolov5 compatible dataset by copying the correct files\n",
    "for country in country_list:\n",
    "    # selects only images from validation in the country \n",
    "    df_country = df[df['cc'] == country]\n",
    "    print(df_country.size)\n",
    "    # new dataset name for each country \n",
    "    new_dataset_name = country + '_ANALYSIS_' + dataset_name\n",
    "\n",
    "    config_val = config['val']\n",
    "    new_config_val = config_val.replace(dataset_name, new_dataset_name)\n",
    "\n",
    "    # copy directory structure \n",
    "    shutil.copytree(os.path.join(folder, dataset_name), os.path.join(folder,new_dataset_name), ignore=ignore_files)\n",
    "    \n",
    "    # for each validation image in the dataframe \n",
    "    for i,f in df_country.iterrows():\n",
    "        old_path_img = os.path.join(config_val, f['path'].replace(\"/\", \"*$\"))\n",
    "        new_path_img = os.path.join(new_config_val, f['path'].replace(\"/\", \"*$\"))\n",
    "        shutil.copy(old_path_img, new_path_img)\n",
    "\n",
    "        old_path_lab = os.path.join(config_val.replace('images', 'labels'), f['path'].replace(\"/\", \"*$\").replace('.JPG', '.txt'))\n",
    "        new_path_lab = os.path.join(new_config_val.replace('images', 'labels'), f['path'].replace(\"/\", \"*$\").replace('.JPG', '.txt'))\n",
    "        shutil.copy(old_path_lab, new_path_lab)\n",
    "\n",
    "    # create new yaml file for the new country dataset \n",
    "    new_yaml_file = yaml_file.replace('data_info', f'data_info_{country}').replace(dataset_name, new_dataset_name)\n",
    "    new_config = config.copy()\n",
    "    # train is not used at all since there will be no training images copied, only validation \n",
    "    new_config['train'] = os.path.join(folder, new_dataset_name, 'train', 'images')\n",
    "    new_config['val'] = os.path.join(folder, new_dataset_name, 'val', 'images')\n",
    "    with open(new_yaml_file, 'w') as outfile:\n",
    "        yaml.dump(new_config, outfile, default_flow_style=False)\n",
    "\n",
    "    # keep track of new yaml files \n",
    "    new_country_yaml_files.append(new_yaml_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpfs/data1/cmongp1/mpaliyam/street2sat/data/UG_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_UG.yaml',\n",
       " '/gpfs/data1/cmongp1/mpaliyam/street2sat/data/KE_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_KE.yaml',\n",
       " '/gpfs/data1/cmongp1/mpaliyam/street2sat/data/US_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_US.yaml']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_country_yaml_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For each new dataset created above, it runs the validation script. This way the per country detection scores can be seen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-2-16 torch 1.10.2+cu102 CUDA:0 (Tesla V100-PCIE-16GB, 16160.5MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "RUNING VALIDATION SCRIPT: /gpfs/data1/cmongp1/mpaliyam/street2sat/data/UG_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_UG.yaml\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/gpfs/data1/cmongp1/mpaliyam/street2sat/data/UG_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_UG.yaml, weights=['/gpfs/data1/cmongp1/mpaliyam/street2sat/yolov5/runs/train/exp18/weights/best.pt'], batch_size=25, imgsz=1000, conf_thres=0.0001, iou_thres=0.1, task=val, device=, single_cls=False, augment=False, verbose=True, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=UG, exist_ok=True, half=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 369 layers, 20919810 parameters, 0 gradients, 48.2 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size 1000 must be multiple of max stride 32, updating to 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/gpfs/data1/cmongp1/mpaliyam/street2sat/data/UG_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/val/labels' images and labels...40 found, 0 missing, 22 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 767.87it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /gpfs/data1/cmongp1/mpaliyam/street2sat/data/UG_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/val/labels.cache\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         40         60      0.702       0.78      0.744      0.332\n",
      "              banana         40         10      0.738        0.8      0.792       0.39\n",
      "               maize         40         50      0.665       0.76      0.696      0.274\n",
      "Speed: 0.3ms pre-process, 12.0ms inference, 1.7ms NMS per image at shape (25, 3, 1024, 1024)\n",
      "Results saved to \u001b[1mruns/val/UG\u001b[0m\n",
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RUNING VALIDATION SCRIPT: /gpfs/data1/cmongp1/mpaliyam/street2sat/data/KE_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_KE.yaml\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/gpfs/data1/cmongp1/mpaliyam/street2sat/data/KE_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_KE.yaml, weights=['/gpfs/data1/cmongp1/mpaliyam/street2sat/yolov5/runs/train/exp18/weights/best.pt'], batch_size=25, imgsz=1000, conf_thres=0.0001, iou_thres=0.1, task=val, device=, single_cls=False, augment=False, verbose=True, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=KE, exist_ok=True, half=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-2-16 torch 1.10.2+cu102 CUDA:0 (Tesla V100-PCIE-16GB, 16160.5MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 369 layers, 20919810 parameters, 0 gradients, 48.2 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size 1000 must be multiple of max stride 32, updating to 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/gpfs/data1/cmongp1/mpaliyam/street2sat/data/KE_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/val/labels' images and labels...18 found, 0 missing, 5 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 1537.44it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /gpfs/data1/cmongp1/mpaliyam/street2sat/data/KE_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/val/labels.cache\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         18         35       0.41      0.656      0.411      0.164\n",
      "               maize         18         35       0.41      0.656      0.411      0.164\n",
      "Speed: 0.3ms pre-process, 12.2ms inference, 1.7ms NMS per image at shape (25, 3, 1024, 1024)\n",
      "Results saved to \u001b[1mruns/val/KE\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-2-16 torch 1.10.2+cu102 CUDA:0 (Tesla V100-PCIE-16GB, 16160.5MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RUNING VALIDATION SCRIPT: /gpfs/data1/cmongp1/mpaliyam/street2sat/data/US_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_US.yaml\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/gpfs/data1/cmongp1/mpaliyam/street2sat/data/US_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/data_info_US.yaml, weights=['/gpfs/data1/cmongp1/mpaliyam/street2sat/yolov5/runs/train/exp18/weights/best.pt'], batch_size=25, imgsz=1000, conf_thres=0.0001, iou_thres=0.1, task=val, device=, single_cls=False, augment=False, verbose=True, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=US, exist_ok=True, half=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 369 layers, 20919810 parameters, 0 gradients, 48.2 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: --img-size 1000 must be multiple of max stride 32, updating to 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/gpfs/data1/cmongp1/mpaliyam/street2sat/data/US_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/val/labels' images and labels...14 found, 0 missing, 8 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 67.64it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /gpfs/data1/cmongp1/mpaliyam/street2sat/data/US_ANALYSIS_DATASET_2022-02-28_01:13:06_474346/val/labels.cache\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         14         25      0.434      0.786      0.499      0.255\n",
      "               maize         14         14      0.303      0.786      0.322      0.179\n",
      "           sugarcane         14          4      0.694          1      0.995      0.534\n",
      "             soybean         14          7      0.305      0.571      0.178     0.0526\n",
      "Speed: 0.3ms pre-process, 13.1ms inference, 4.2ms NMS per image at shape (25, 3, 1024, 1024)\n",
      "Results saved to \u001b[1mruns/val/US\u001b[0m\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# runs validation script on each of the country\n",
    "for country_yaml_file in new_country_yaml_files:\n",
    "    print(f\"\\n\\n\\n\\nRUNING VALIDATION SCRIPT: {country_yaml_file}\\n\\n\\n\")\n",
    "    # gets the country code\n",
    "    exp_name = country_yaml_file.split('_')[0][-2:]\n",
    "    # runs the validate script from yolov5 libary\n",
    "    to_parse = f\"val.py --data {country_yaml_file} \" \\\n",
    "                + f\"--weights {model_weights_path} \" \\\n",
    "                + f\"--batch-size {batch_size} \" \\\n",
    "                + f\"--imgsz {img_size} \" \\\n",
    "                + f\"--conf-thres {conf_thresh} \" \\\n",
    "                + f\"--iou-thres {iou_thresh} \" \\\n",
    "                + f\"--project {save_folder} \"\\\n",
    "                + f\"--name {exp_name} \"\\\n",
    "                + f\"--verbose \" \\\n",
    "                + f\"--exist-ok \" \\\n",
    "                + f\"--task val\"\\\n",
    "\n",
    "    to_parse = to_parse.split()\n",
    "    sys.argv = to_parse \n",
    "    val.main()\n",
    "\n",
    "    print(\"------------------------------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e19b068c9dc8e9abbb63f4ebe6ba72967bfa9808ead93b8c4d20f84e90dab6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('mads')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
